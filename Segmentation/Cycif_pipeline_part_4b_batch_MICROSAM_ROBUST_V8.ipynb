{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a05a85f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Basic imports\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"KMP_DUPLICATE_LIB_OK\"] = \"TRUE\"\n",
    "\n",
    "import sys\n",
    "import gc\n",
    "import pickle\n",
    "import shutil\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tifffile\n",
    "import json\n",
    "import psutil\n",
    "from pathlib import Path\n",
    "from scipy import ndimage as ndi\n",
    "from skimage import morphology\n",
    "from skimage.measure import label, regionprops, find_contours\n",
    "from tqdm.auto import tqdm\n",
    "import time\n",
    "from datetime import datetime\n",
    "\n",
    "print(\"âœ“ Basic imports\")\n",
    "\n",
    "import torch\n",
    "from micro_sam.util import get_sam_model\n",
    "from micro_sam.instance_segmentation import (\n",
    "    AutomaticMaskGenerator,\n",
    "    mask_data_to_segmentation\n",
    ")\n",
    "print(f\"âœ“ PyTorch: {torch.__version__}\")\n",
    "print(f\"âœ“ Micro-SAM imported\")\n",
    "print(f\"âœ“ Available RAM: {psutil.virtual_memory().available / (1024**3):.1f} GB\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1f102f8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Path' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# === CONFIGURATION ===\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m DATA_ROOT = \u001b[43mPath\u001b[49m(\u001b[33mr\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mC:\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mUsers\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mresearcher\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mscimap-master\u001b[39m\u001b[33m\\\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Only the 4 remaining samples\u001b[39;00m\n\u001b[32m      5\u001b[39m ALL_SAMPLES = [\n\u001b[32m      6\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33msample_209\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msample_215\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msample_220\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33msample_222\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m      7\u001b[39m ]\n",
      "\u001b[31mNameError\u001b[39m: name 'Path' is not defined"
     ]
    }
   ],
   "source": [
    "# === CONFIGURATION ===\n",
    "DATA_ROOT = Path(r\"C:\\Users\\researcher\\data\\scimap-master\\data\")\n",
    "\n",
    "# Only the 4 remaining samples\n",
    "ALL_SAMPLES = [\n",
    "    \"sample_209\", \"sample_215\", \"sample_220\", \"sample_222\"\n",
    "]\n",
    "\n",
    "# Optional skip list\n",
    "SKIP_SAMPLES = []  # Set to [\"sample_215\"] to skip 13GB monster\n",
    "\n",
    "# Model\n",
    "MODEL_TYPE = 'vit_b'\n",
    "\n",
    "# ADAPTIVE TILE SIZING - PIXEL-BASED\n",
    "TILE_SIZE_NORMAL = 1024      # <60M pixels\n",
    "TILE_SIZE_MONSTER = 512      # 60-80M pixels\n",
    "TILE_SIZE_ULTRA = 384        # >80M pixels (prevents VS Code crash)\n",
    "OVERLAP = 256\n",
    "MIN_OBJECT_SIZE = 8000\n",
    "\n",
    "# Pixel count thresholds for adaptive tile sizing\n",
    "MONSTER_PIXEL_THRESHOLD = 60_000_000  # 60M pixels\n",
    "ULTRA_PIXEL_THRESHOLD = 80_000_000    # 80M pixels (sample_222 = 90.6M)\n",
    "\n",
    "# CHUNKED PROCESSING - ADAPTIVE BY IMAGE SIZE\n",
    "MASK_BATCH_SIZE = 10  # Base: 10 masks\n",
    "MASK_BATCH_SIZE_MONSTER = 6  # For huge images (60-80M px): 6 masks\n",
    "MASK_BATCH_SIZE_ULTRA = 4    # For ultra images (>80M px): 4 masks â†’ 12 GB max\n",
    "TILE_LOAD_BATCH = 10  # Base: 10 tiles\n",
    "TILE_LOAD_BATCH_MONSTER = 5  # For huge images: 5 tiles\n",
    "TILE_LOAD_BATCH_ULTRA = 3    # For ultra images: 3 tiles â†’ 10 GB max\n",
    "\n",
    "# Disk caching\n",
    "TEMP_DIR = Path(r\"C:\\Users\\researcher\\Downloads\\Cycif_pipeline_V3\\temp_tiles_v8\")\n",
    "TEMP_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Use V5 checkpoint\n",
    "CHECKPOINT_FILE = Path(r\"C:\\Users\\researcher\\Downloads\\Cycif_pipeline_V3\\batch_progress_v5.json\")\n",
    "\n",
    "# Filtering\n",
    "MIN_AREA = 8000\n",
    "MAX_AREA = 100000\n",
    "MAX_ECCENTRICITY = 0.9\n",
    "\n",
    "# Morphology\n",
    "APPLY_MORPHOLOGY = True\n",
    "MERGE_RADIUS = 15\n",
    "SMOOTH_RADIUS = 5\n",
    "\n",
    "# RAM safety - STRICT\n",
    "MIN_FREE_RAM_GB = 8.0  # Don't start if <8GB free\n",
    "MIN_SAFE_RAM_GB = 5.0  # Pause processing if drops below 5GB\n",
    "PAUSE_BETWEEN_SAMPLES = 15  # Longer pause for GC\n",
    "\n",
    "print(f\"Data: {DATA_ROOT}\")\n",
    "print(f\"Samples: {len(ALL_SAMPLES)}\")\n",
    "if SKIP_SAMPLES:\n",
    "    print(f\"âš ï¸  Skipping: {SKIP_SAMPLES}\")\n",
    "print(f\"Adaptive tiles: {TILE_SIZE_NORMAL}px â†’ {TILE_SIZE_MONSTER}px â†’ {TILE_SIZE_ULTRA}px\")\n",
    "print(f\"Pixel thresholds: <60M â†’ 60-80M â†’ >80M\")\n",
    "print(f\"Mask batch: {MASK_BATCH_SIZE} â†’ {MASK_BATCH_SIZE_MONSTER} â†’ {MASK_BATCH_SIZE_ULTRA}\")\n",
    "print(f\"Tile load: {TILE_LOAD_BATCH} â†’ {TILE_LOAD_BATCH_MONSTER} â†’ {TILE_LOAD_BATCH_ULTRA}\")\n",
    "print(f\"Temp: {TEMP_DIR}\")\n",
    "print(f\"Checkpoint: {CHECKPOINT_FILE}\")\n",
    "print(f\"RAM gate: {MIN_FREE_RAM_GB} GB minimum, {MIN_SAFE_RAM_GB} GB safe threshold\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64137b12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Checkpoint & RAM management ready\n"
     ]
    }
   ],
   "source": [
    "# === CHECKPOINT & RAM MANAGEMENT ===\n",
    "def load_checkpoint():\n",
    "    if CHECKPOINT_FILE.exists():\n",
    "        try:\n",
    "            with open(CHECKPOINT_FILE, 'r') as f:\n",
    "                data = json.load(f)\n",
    "            success_count = len([r for r in data.get('results', []) if r.get('status') == 'success'])\n",
    "            print(f\"âœ“ Checkpoint: {success_count} successful\")\n",
    "            return data\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  Checkpoint error: {e}\")\n",
    "    return {'completed': [], 'failed': [], 'results': []}\n",
    "\n",
    "def save_checkpoint(data):\n",
    "    for attempt in range(3):\n",
    "        try:\n",
    "            with open(CHECKPOINT_FILE, 'w') as f:\n",
    "                json.dump(data, f, indent=2)\n",
    "            return\n",
    "        except Exception as e:\n",
    "            if attempt == 2:\n",
    "                print(f\"âš ï¸  Checkpoint save failed: {e}\")\n",
    "            time.sleep(0.5)\n",
    "\n",
    "def get_remaining_samples(checkpoint_data):\n",
    "    successful = set()\n",
    "    for result in checkpoint_data.get('results', []):\n",
    "        if result.get('status') == 'success':\n",
    "            successful.add(result['sample_id'])\n",
    "    return [s for s in ALL_SAMPLES if s not in successful and s not in SKIP_SAMPLES]\n",
    "\n",
    "def check_ram(min_required=MIN_FREE_RAM_GB, context=\"\"):\n",
    "    mem = psutil.virtual_memory()\n",
    "    free_gb = mem.available / (1024**3)\n",
    "    if free_gb < min_required:\n",
    "        print(f\"âš ï¸  LOW RAM: {free_gb:.1f} GB (need {min_required} GB) - {context}\")\n",
    "    return free_gb\n",
    "\n",
    "def wait_for_ram(min_required=MIN_SAFE_RAM_GB, max_wait=60):\n",
    "    \"\"\"Wait for RAM to free up.\"\"\"\n",
    "    start = time.time()\n",
    "    while time.time() - start < max_wait:\n",
    "        free_gb = psutil.virtual_memory().available / (1024**3)\n",
    "        if free_gb >= min_required:\n",
    "            return True\n",
    "        print(f\"    Waiting for RAM... ({free_gb:.1f} GB free)\")\n",
    "        gc.collect()\n",
    "        time.sleep(5)\n",
    "    return False\n",
    "\n",
    "def get_adaptive_tile_size_by_pixels(num_pixels):\n",
    "    \"\"\"Pixel-based adaptive tile sizing to prevent VS Code crashes\"\"\"\n",
    "    if num_pixels > ULTRA_PIXEL_THRESHOLD:\n",
    "        return TILE_SIZE_ULTRA, \"ULTRA\"\n",
    "    elif num_pixels > MONSTER_PIXEL_THRESHOLD:\n",
    "        return TILE_SIZE_MONSTER, \"MONSTER\"\n",
    "    else:\n",
    "        return TILE_SIZE_NORMAL, \"NORMAL\"\n",
    "\n",
    "print(\"âœ“ Checkpoint & RAM management ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9abcc7a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Samples (smallest first):\n",
      "  sample_222: 7676.5 MB â†’ 1024px tiles (NORMAL)\n",
      "  sample_220: 9313.0 MB â†’ 768px tiles (LARGE)\n",
      "  sample_209: 9664.7 MB â†’ 768px tiles (LARGE)\n",
      "  sample_215: 13421.8 MB â†’ 512px tiles (MONSTER)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === SORT BY SIZE (PIXEL-BASED CATEGORIZATION) ===\n",
    "sample_sizes = []\n",
    "for sample_id in ALL_SAMPLES:\n",
    "    if sample_id in SKIP_SAMPLES:\n",
    "        continue\n",
    "    input_path = DATA_ROOT / sample_id / \"AF_removal\" / \"fused_decon_AF_cleaned.ome.tif\"\n",
    "    if input_path.exists():\n",
    "        size_mb = input_path.stat().st_size / (1024 * 1024)\n",
    "        # Get image dimensions to determine tile size\n",
    "        try:\n",
    "            with tifffile.TiffFile(input_path) as tif:\n",
    "                img_shape = tif.series[0].shape\n",
    "                if len(img_shape) == 3:  # (C, H, W)\n",
    "                    h, w = img_shape[1], img_shape[2]\n",
    "                elif len(img_shape) == 2:  # (H, W)\n",
    "                    h, w = img_shape\n",
    "                else:\n",
    "                    h, w = 0, 0\n",
    "                num_pixels = h * w\n",
    "                tile_size, category = get_adaptive_tile_size_by_pixels(num_pixels)\n",
    "                sample_sizes.append((sample_id, size_mb, tile_size, category, num_pixels, h, w))\n",
    "        except Exception as e:\n",
    "            print(f\"âš ï¸  {sample_id}: Could not read dimensions: {e}\")\n",
    "            sample_sizes.append((sample_id, size_mb, 1024, \"UNKNOWN\", 0, 0, 0))\n",
    "    else:\n",
    "        sample_sizes.append((sample_id, float('inf'), 0, \"MISSING\", 0, 0, 0))\n",
    "\n",
    "sample_sizes.sort(key=lambda x: x[1])\n",
    "SORTED_SAMPLES = [s[0] for s in sample_sizes]\n",
    "\n",
    "print(\"Samples (smallest first):\")\n",
    "for sid, size, tiles, cat, npx, h, w in sample_sizes:\n",
    "    if size == float('inf'):\n",
    "        print(f\"  {sid}: MISSING\")\n",
    "    elif npx > 0:\n",
    "        mpx = npx / 1_000_000\n",
    "        print(f\"  {sid}: {size:.1f} MB, {h}Ã—{w} ({mpx:.1f}M px) â†’ {tiles}px tiles ({cat})\")\n",
    "    else:\n",
    "        print(f\"  {sid}: {size:.1f} MB â†’ {tiles}px tiles ({cat})\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4573d222",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading vit_b...\n",
      "âœ“ Model loaded\n",
      "\n",
      "âœ“ Model loaded\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === LOAD MODEL ===\n",
    "check_ram(context=\"before model load\")\n",
    "print(f\"Loading {MODEL_TYPE}...\")\n",
    "predictor = get_sam_model(model_type=MODEL_TYPE, checkpoint_path=None, device='cpu')\n",
    "print(\"âœ“ Model loaded\")\n",
    "check_ram(context=\"after model load\")\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4dcd211d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Helper functions ready (RLE + triple-chunked: Normal/Monster/Ultra)\n",
      "âœ“ Helper functions ready (RLE + double-chunked processing)\n",
      "âœ“ Helper functions ready (RLE + double-chunked processing)\n"
     ]
    }
   ],
   "source": [
    "# === HELPER FUNCTIONS ===\n",
    "\n",
    "def rle_encode(mask):\n",
    "    \"\"\"RLE encoding for boolean mask.\"\"\"\n",
    "    pixels = mask.flatten()\n",
    "    pixels = np.concatenate([[0], pixels, [0]])\n",
    "    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n",
    "    runs[1::2] -= runs[::2]\n",
    "    return runs\n",
    "\n",
    "def rle_decode(rle, shape):\n",
    "    \"\"\"Decode RLE to boolean mask.\"\"\"\n",
    "    starts, lengths = rle[::2], rle[1::2]\n",
    "    starts -= 1\n",
    "    ends = starts + lengths\n",
    "    mask = np.zeros(shape[0] * shape[1], dtype=bool)\n",
    "    for start, end in zip(starts, ends):\n",
    "        mask[start:end] = True\n",
    "    return mask.reshape(shape)\n",
    "\n",
    "\n",
    "def find_laminin_channel(sample_dir, sample_id):\n",
    "    marker_csv = sample_dir / f\"markers_{sample_id.split('_')[-1]}.csv\"\n",
    "    if not marker_csv.exists():\n",
    "        candidates = list(sample_dir.glob(\"markers_*.csv\"))\n",
    "        if not candidates:\n",
    "            return None, None, \"Marker CSV not found\"\n",
    "        marker_csv = candidates[0]\n",
    "    \n",
    "    try:\n",
    "        markers_df = pd.read_csv(marker_csv)\n",
    "    except Exception as e:\n",
    "        return None, None, f\"CSV error: {e}\"\n",
    "    \n",
    "    marker_col = None\n",
    "    for col in ['Marker-Name', 'marker_name', 'Marker', 'marker', 'name', 'Name']:\n",
    "        if col in markers_df.columns:\n",
    "            marker_col = col\n",
    "            break\n",
    "    \n",
    "    if not marker_col:\n",
    "        return None, None, \"Marker column not found\"\n",
    "    \n",
    "    laminin_rows = markers_df[markers_df[marker_col].fillna('').str.upper().str.contains('LAMININ')]\n",
    "    if laminin_rows.empty:\n",
    "        return None, None, \"Laminin not found\"\n",
    "    \n",
    "    include_col = None\n",
    "    for col in ['Include', 'include', 'included', 'Included']:\n",
    "        if col in markers_df.columns:\n",
    "            include_col = col\n",
    "            break\n",
    "    \n",
    "    if include_col:\n",
    "        included = laminin_rows[laminin_rows[include_col] == True]\n",
    "        row = included.iloc[0] if not included.empty else laminin_rows.iloc[0]\n",
    "    else:\n",
    "        row = laminin_rows.iloc[0]\n",
    "    \n",
    "    csv_pos = markers_df.index.get_loc(row.name)\n",
    "    \n",
    "    if include_col:\n",
    "        mask = markers_df[include_col] == True\n",
    "        idx = len(markers_df.iloc[:csv_pos][mask.iloc[:csv_pos]])\n",
    "    else:\n",
    "        idx = csv_pos\n",
    "    \n",
    "    return idx, row[marker_col], None\n",
    "\n",
    "\n",
    "def extract_channel_memmap(tiff_path, channel_idx):\n",
    "    try:\n",
    "        with tifffile.TiffFile(tiff_path) as tif:\n",
    "            series = tif.series[0]\n",
    "            if channel_idx >= len(series):\n",
    "                raise ValueError(f\"Channel {channel_idx} out of range\")\n",
    "            \n",
    "            page = series.pages[channel_idx]\n",
    "            img = page.asarray()\n",
    "            \n",
    "            img_float = img.astype(np.float32)\n",
    "            del img\n",
    "            gc.collect()\n",
    "            \n",
    "            vmin, vmax = np.percentile(img_float, [1, 99.5])\n",
    "            img_norm = np.clip((img_float - vmin) / (vmax - vmin), 0, 1)\n",
    "            del img_float\n",
    "            gc.collect()\n",
    "            \n",
    "            img_uint8 = (img_norm * 255).astype(np.uint8)\n",
    "            del img_norm\n",
    "            gc.collect()\n",
    "            \n",
    "            return img_uint8, None\n",
    "    except Exception as e:\n",
    "        return None, f\"Channel extraction error: {e}\"\n",
    "\n",
    "\n",
    "def segment_with_tiles_rle_compressed(image_uint8, predictor, sample_id, tile_size, overlap=256):\n",
    "    \"\"\"Segment tiles and save with RLE compression.\"\"\"\n",
    "    h, w = image_uint8.shape\n",
    "    n_y = int(np.ceil(h / (tile_size - overlap)))\n",
    "    n_x = int(np.ceil(w / (tile_size - overlap)))\n",
    "    total = n_y * n_x\n",
    "    \n",
    "    print(f\"    Tiles: {total} ({n_y}Ã—{n_x} at {tile_size}px)\")\n",
    "    \n",
    "    temp_sample = TEMP_DIR / sample_id\n",
    "    temp_sample.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    tile_files = []\n",
    "    skipped = 0\n",
    "    \n",
    "    with tqdm(total=total, desc=\"  Segmenting tiles\", leave=False) as pbar:\n",
    "        for i in range(n_y):\n",
    "            for j in range(n_x):\n",
    "                # Check RAM every 5 tiles\n",
    "                if (i * n_x + j) % 5 == 0:\n",
    "                    free_gb = check_ram(MIN_SAFE_RAM_GB, f\"tile [{i},{j}]\")\n",
    "                    if free_gb < MIN_SAFE_RAM_GB:\n",
    "                        print(f\"\\n    Waiting for RAM...\")\n",
    "                        wait_for_ram(MIN_SAFE_RAM_GB)\n",
    "                \n",
    "                y0 = i * (tile_size - overlap)\n",
    "                x0 = j * (tile_size - overlap)\n",
    "                y1 = min(y0 + tile_size, h)\n",
    "                x1 = min(x0 + tile_size, w)\n",
    "                \n",
    "                tile = image_uint8[y0:y1, x0:x1].copy()\n",
    "                \n",
    "                try:\n",
    "                    gen = AutomaticMaskGenerator(predictor)\n",
    "                    gen.initialize(tile)\n",
    "                    masks = gen.generate()\n",
    "                    \n",
    "                    # RLE compress each mask\n",
    "                    compact_masks = []\n",
    "                    for m in masks:\n",
    "                        seg_tile = m['segmentation']  # bool array in tile coords\n",
    "                        bbox_tile = m['bbox']  # [x, y, w, h] in tile coords\n",
    "                        \n",
    "                        # Extract bbox region only\n",
    "                        x_t, y_t, w_t, h_t = bbox_tile\n",
    "                        seg_bbox = seg_tile[y_t:y_t+h_t, x_t:x_t+w_t]\n",
    "                        \n",
    "                        # RLE encode\n",
    "                        rle = rle_encode(seg_bbox)\n",
    "                        \n",
    "                        # Store compact data\n",
    "                        compact_masks.append({\n",
    "                            'rle': rle,\n",
    "                            'bbox_shape': (h_t, w_t),\n",
    "                            'bbox_global': [x_t + x0, y_t + y0, w_t, h_t],\n",
    "                            'area': m['area'],\n",
    "                            'predicted_iou': m.get('predicted_iou', 0.0)\n",
    "                        })\n",
    "                    \n",
    "                    # Save compressed tile\n",
    "                    pkl_file = temp_sample / f\"tile_{i:03d}_{j:03d}.pkl\"\n",
    "                    with open(pkl_file, 'wb') as f:\n",
    "                        pickle.dump(compact_masks, f, protocol=4)\n",
    "                    tile_files.append(pkl_file)\n",
    "                    \n",
    "                    del masks, gen, tile, compact_masks, seg_tile, seg_bbox\n",
    "                    gc.collect()\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    skipped += 1\n",
    "                    print(f\"\\n    âš ï¸  Tile [{i},{j}]: {type(e).__name__}: {str(e)[:80]}\")\n",
    "                    del tile\n",
    "                    gc.collect()\n",
    "                \n",
    "                pbar.update(1)\n",
    "    \n",
    "    if skipped > 0:\n",
    "        print(f\"    âš ï¸  {skipped} tiles skipped\")\n",
    "    \n",
    "    return tile_files, (h, w)\n",
    "\n",
    "\n",
    "def load_tiles_chunked(tile_files, img_shape, chunk_size=None):\n",
    "    \"\"\"Load and decode RLE tiles in chunks to avoid RAM overflow.\"\"\"\n",
    "    h, w = img_shape\n",
    "    \n",
    "    # Auto-determine chunk size based on image size\n",
    "    if chunk_size is None:\n",
    "        img_pixels = h * w\n",
    "        if img_pixels > 80_000_000:  # >80M pixels (e.g., 9500Ã—9500)\n",
    "            chunk_size = TILE_LOAD_BATCH_ULTRA\n",
    "        elif img_pixels > 60_000_000:  # >60M pixels (e.g., 10000Ã—7000)\n",
    "            chunk_size = TILE_LOAD_BATCH_MONSTER\n",
    "        else:\n",
    "            chunk_size = TILE_LOAD_BATCH\n",
    "    \n",
    "    all_masks = []\n",
    "    n_chunks = int(np.ceil(len(tile_files) / chunk_size))\n",
    "    \n",
    "    print(f\"    Loading {len(tile_files)} tiles in {n_chunks} chunks of {chunk_size}...\")\n",
    "    \n",
    "    for chunk_idx in range(n_chunks):\n",
    "        start_idx = chunk_idx * chunk_size\n",
    "        end_idx = min((chunk_idx + 1) * chunk_size, len(tile_files))\n",
    "        chunk_files = tile_files[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"      Chunk {chunk_idx+1}/{n_chunks}: {len(chunk_files)} tiles\")\n",
    "        \n",
    "        for pkl_file in chunk_files:\n",
    "            try:\n",
    "                with open(pkl_file, 'rb') as f:\n",
    "                    compact_masks = pickle.load(f)\n",
    "                \n",
    "                # Decode each mask\n",
    "                for cm in compact_masks:\n",
    "                    # Decode RLE to bbox-sized mask\n",
    "                    seg_bbox = rle_decode(cm['rle'], cm['bbox_shape'])\n",
    "                    \n",
    "                    # Create full-size sparse mask\n",
    "                    seg_full = np.zeros((h, w), dtype=bool)\n",
    "                    x_g, y_g, w_g, h_g = cm['bbox_global']\n",
    "                    seg_full[y_g:y_g+h_g, x_g:x_g+w_g] = seg_bbox\n",
    "                    \n",
    "                    all_masks.append({\n",
    "                        'segmentation': seg_full,\n",
    "                        'bbox': cm['bbox_global'],\n",
    "                        'area': cm['area'],\n",
    "                        'predicted_iou': cm['predicted_iou'],\n",
    "                        'stability_score': 0.0\n",
    "                    })\n",
    "                    \n",
    "                    del seg_bbox, seg_full\n",
    "                \n",
    "                del compact_masks\n",
    "                pkl_file.unlink()  # Delete as we go\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"      âš ï¸  Load {pkl_file.name}: {e}\")\n",
    "        \n",
    "        # GC after each chunk\n",
    "        gc.collect()\n",
    "    \n",
    "    return all_masks\n",
    "\n",
    "\n",
    "def masks_to_segmentation_chunked(masks, img_shape, batch_size=None, min_object_size=MIN_OBJECT_SIZE):\n",
    "    \"\"\"Process masks in batches to avoid RAM explosion.\"\"\"\n",
    "    h, w = img_shape\n",
    "    \n",
    "    # Auto-determine batch size based on image size\n",
    "    if batch_size is None:\n",
    "        img_pixels = h * w\n",
    "        if img_pixels > 80_000_000:  # >80M pixels\n",
    "            batch_size = MASK_BATCH_SIZE_ULTRA\n",
    "        elif img_pixels > 60_000_000:  # >60M pixels\n",
    "            batch_size = MASK_BATCH_SIZE_MONSTER\n",
    "        else:\n",
    "            batch_size = MASK_BATCH_SIZE\n",
    "    \n",
    "    print(f\"    Converting {len(masks)} masks in batches of {batch_size}...\")\n",
    "    \n",
    "    final_seg = np.zeros((h, w), dtype=np.uint32)\n",
    "    current_label = 1\n",
    "    \n",
    "    num_batches = int(np.ceil(len(masks) / batch_size))\n",
    "    \n",
    "    for batch_idx in range(num_batches):\n",
    "        start_idx = batch_idx * batch_size\n",
    "        end_idx = min((batch_idx + 1) * batch_size, len(masks))\n",
    "        batch_masks = masks[start_idx:end_idx]\n",
    "        \n",
    "        print(f\"      Batch {batch_idx+1}/{num_batches}: {len(batch_masks)} masks\")\n",
    "        \n",
    "        # Check RAM\n",
    "        free_gb = check_ram(MIN_SAFE_RAM_GB, f\"batch {batch_idx+1}\")\n",
    "        if free_gb < MIN_SAFE_RAM_GB:\n",
    "            wait_for_ram(MIN_SAFE_RAM_GB)\n",
    "        \n",
    "        try:\n",
    "            # Convert batch\n",
    "            batch_seg = mask_data_to_segmentation(\n",
    "                batch_masks, \n",
    "                with_background=True, \n",
    "                min_object_size=min_object_size\n",
    "            )\n",
    "            \n",
    "            # Merge into final\n",
    "            for label_id in np.unique(batch_seg):\n",
    "                if label_id == 0:\n",
    "                    continue\n",
    "                mask = batch_seg == label_id\n",
    "                final_seg[mask & (final_seg == 0)] = current_label\n",
    "                current_label += 1\n",
    "            \n",
    "            del batch_seg, batch_masks\n",
    "            gc.collect()\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"      âš ï¸  Batch {batch_idx+1} failed: {e}\")\n",
    "            del batch_masks\n",
    "            gc.collect()\n",
    "            continue\n",
    "    \n",
    "    print(f\"    â†’ {current_label - 1} objects\")\n",
    "    return final_seg\n",
    "\n",
    "\n",
    "def filter_by_size_shape(seg, min_a, max_a, max_e):\n",
    "    props = regionprops(seg)\n",
    "    filt = np.zeros_like(seg)\n",
    "    for p in props:\n",
    "        if min_a <= p.area <= max_a and p.eccentricity <= max_e:\n",
    "            filt[seg == p.label] = p.label\n",
    "    return label(filt > 0)\n",
    "\n",
    "\n",
    "def apply_morphological_refinement(mask, min_a, merge_r=15, smooth_r=5):\n",
    "    binary = mask > 0\n",
    "    binary = morphology.binary_closing(binary, morphology.disk(merge_r))\n",
    "    binary = ndi.binary_fill_holes(binary)\n",
    "    binary = morphology.binary_closing(binary, morphology.disk(smooth_r))\n",
    "    binary = morphology.remove_small_objects(binary, min_size=min_a)\n",
    "    return label(binary)\n",
    "\n",
    "\n",
    "def save_outputs(final_mask, output_dir, sample_id, marker_name):\n",
    "    output_dir.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    bin_path = output_dir / \"crypt_mask_microsam.tif\"\n",
    "    lab_path = output_dir / \"crypt_mask_microsam_labeled.tif\"\n",
    "    tifffile.imwrite(bin_path, ((final_mask > 0).astype(np.uint8) * 255), compression='zlib')\n",
    "    tifffile.imwrite(lab_path, final_mask.astype(np.uint16), compression='zlib')\n",
    "    \n",
    "    reg_path = output_dir / \"segment_registry.csv\"\n",
    "    entries = []\n",
    "    for cid in np.unique(final_mask[final_mask > 0]):\n",
    "        entries.append({\n",
    "            'segment_id': int(cid),\n",
    "            'segment_type': 'crypt_microsam',\n",
    "            'mask_file': lab_path.name,\n",
    "            'global_unique_id': f\"M_{int(cid)}\",\n",
    "            'sample_id': sample_id,\n",
    "            'marker': marker_name,\n",
    "            'method': 'MicroSAM'\n",
    "        })\n",
    "    \n",
    "    reg_df = pd.DataFrame(entries)\n",
    "    if reg_path.exists():\n",
    "        exist = pd.read_csv(reg_path)\n",
    "        exist = exist[~((exist['segment_type'] == 'crypt_microsam') & (exist['sample_id'] == sample_id))]\n",
    "        reg_df = pd.concat([exist, reg_df], ignore_index=True)\n",
    "    reg_df.to_csv(reg_path, index=False)\n",
    "    \n",
    "    geo_path = output_dir / f\"{sample_id}_crypts_microsam_qupath.geojson\"\n",
    "    features = []\n",
    "    for p in regionprops(final_mask):\n",
    "        cb = (final_mask == p.label).astype(np.uint8)\n",
    "        contours = find_contours(cb, level=0.5)\n",
    "        if not contours:\n",
    "            continue\n",
    "        cnt = max(contours, key=len)\n",
    "        coords = [[float(x), float(y)] for y, x in cnt]\n",
    "        if coords[0] != coords[-1]:\n",
    "            coords.append(coords[0])\n",
    "        \n",
    "        features.append({\n",
    "            \"type\": \"Feature\",\n",
    "            \"id\": f\"M_{p.label}\",\n",
    "            \"geometry\": {\"type\": \"Polygon\", \"coordinates\": [coords]},\n",
    "            \"properties\": {\n",
    "                \"classification\": {\"name\": \"Crypt\", \"colorRGB\": -3140401},\n",
    "                \"object_type\": \"annotation\",\n",
    "                \"name\": f\"Crypt_{p.label}\",\n",
    "                \"isLocked\": False,\n",
    "                \"measurements\": {\n",
    "                    \"Area_um2\": float(p.area),\n",
    "                    \"Perimeter_um\": float(p.perimeter),\n",
    "                    \"Eccentricity\": float(p.eccentricity),\n",
    "                    \"Solidity\": float(p.solidity)\n",
    "                },\n",
    "                \"segment_id\": int(p.label),\n",
    "                \"global_id\": f\"M_{p.label}\",\n",
    "                \"sample_id\": sample_id,\n",
    "                \"method\": \"MicroSAM\"\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    with open(geo_path, 'w') as f:\n",
    "        json.dump({\"type\": \"FeatureCollection\", \"features\": features}, f, indent=2)\n",
    "    \n",
    "print(\"âœ“ Helper functions ready (RLE + triple-chunked: Normal/Monster/Ultra)\")\n",
    "print(\"âœ“ Helper functions ready (RLE + double-chunked processing)\")\n",
    "print(\"âœ“ Helper functions ready (RLE + double-chunked processing)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "494d7020",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Checkpoint: 5 successful\n",
      "\n",
      "================================================================================\n",
      "BATCH V8 - 4 SAMPLES\n",
      "================================================================================\n",
      "Time: 2025-11-17 07:21:02\n",
      "Remaining: ['sample_222', 'sample_220', 'sample_209', 'sample_215']\n",
      "\n",
      "\n",
      "[1/4] sample_222...\n",
      "  File: 7676.5 MB (NORMAL) â†’ 1024px tiles\n",
      "  Finding Laminin...\n",
      "    'Laminin_c12' at ch67\n",
      "  Extracting channel (memory-mapped)...\n",
      "    9523Ã—9515 px\n",
      "  Segmenting with 1024px tiles (RLE compression)...\n",
      "    Tiles: 169 (13Ã—13 at 1024px)\n",
      "    9523Ã—9515 px\n",
      "  Segmenting with 1024px tiles (RLE compression)...\n",
      "    Tiles: 169 (13Ã—13 at 1024px)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "34c5699dd4d3491ba7fc2d01fbdf4b0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  Segmenting tiles:   0%|          | 0/169 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:04<00:00,  4.16s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.39s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.56s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.72s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.68s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.58s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.65s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.58s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.67s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.71s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.62s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.58s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.63s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.59s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.61s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.69s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.60s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.53s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.57s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.45s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.64s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.56s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.49s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.41s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.42s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.40s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.43s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.55s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.70s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.47s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.48s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.66s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.46s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.44s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.54s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.50s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.51s/it]\n",
      "\n",
      "Compute Image Embeddings 2D: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:03<00:00,  3.52s/it]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# === BATCH PROCESSING V8 ===\n",
    "\n",
    "checkpoint = load_checkpoint()\n",
    "remaining = get_remaining_samples(checkpoint)\n",
    "remaining_sorted = [s for s in SORTED_SAMPLES if s in remaining]\n",
    "\n",
    "if not remaining_sorted:\n",
    "    print(\"\\nâœ“ ALL SAMPLES COMPLETED!\\n\")\n",
    "else:\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(f\"BATCH V8 - {len(remaining_sorted)} SAMPLES\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Time: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\")\n",
    "    print(f\"Remaining: {remaining_sorted}\\n\")\n",
    "    \n",
    "    overall_start = time.time()\n",
    "    \n",
    "    for idx, sample_id in enumerate(remaining_sorted, 1):\n",
    "        print(f\"\\n[{idx}/{len(remaining_sorted)}] {sample_id}...\")\n",
    "        \n",
    "        # RAM GATE\n",
    "        free_gb = check_ram(MIN_FREE_RAM_GB, \"start gate\")\n",
    "        if free_gb < MIN_FREE_RAM_GB:\n",
    "            print(f\"  âœ— SKIP: Insufficient RAM ({free_gb:.1f} GB)\")\n",
    "            print(\"    Please restart kernel\")\n",
    "            checkpoint['results'].append({\n",
    "                'sample_id': sample_id,\n",
    "                'status': 'failed',\n",
    "                'num_crypts': 0,\n",
    "                'time_seconds': 0,\n",
    "                'error': f'Insufficient RAM: {free_gb:.1f} GB'\n",
    "            })\n",
    "            save_checkpoint(checkpoint)\n",
    "            continue\n",
    "        \n",
    "        sample_start = time.time()\n",
    "        \n",
    "        try:\n",
    "            sample_dir = DATA_ROOT / sample_id\n",
    "            input_path = sample_dir / \"AF_removal\" / \"fused_decon_AF_cleaned.ome.tif\"\n",
    "            output_dir = sample_dir / \"crypt_segmentation\"\n",
    "            \n",
    "            if not input_path.exists():\n",
    "                print(\"  âš ï¸  SKIP: Input missing\")\n",
    "                checkpoint['results'].append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'status': 'failed',\n",
    "                    'num_crypts': 0,\n",
    "                    'time_seconds': time.time() - sample_start,\n",
    "                    'error': 'Input missing'\n",
    "                })\n",
    "                save_checkpoint(checkpoint)\n",
    "                continue\n",
    "            \n",
    "            size_mb = input_path.stat().st_size / (1024 * 1024)\n",
    "            \n",
    "            # Get image dimensions for pixel-based tile sizing\n",
    "            with tifffile.TiffFile(input_path) as tif:\n",
    "                img_shape = tif.series[0].shape\n",
    "                if len(img_shape) == 3:  # (C, H, W)\n",
    "                    h, w = img_shape[1], img_shape[2]\n",
    "                else:  # (H, W)\n",
    "                    h, w = img_shape\n",
    "                num_pixels = h * w\n",
    "            \n",
    "            tile_size, category = get_adaptive_tile_size_by_pixels(num_pixels)\n",
    "            mpx = num_pixels / 1_000_000\n",
    "            print(f\"  File: {size_mb:.1f} MB, {h}Ã—{w} ({mpx:.1f}M px) â†’ {tile_size}px tiles ({category})\")\n",
    "            \n",
    "            print(\"  Finding Laminin...\")\n",
    "            ch_idx, marker, error = find_laminin_channel(sample_dir, sample_id)\n",
    "            if error:\n",
    "                print(f\"  âš ï¸  SKIP: {error}\")\n",
    "                checkpoint['results'].append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'status': 'failed',\n",
    "                    'num_crypts': 0,\n",
    "                    'time_seconds': time.time() - sample_start,\n",
    "                    'error': error\n",
    "                })\n",
    "                save_checkpoint(checkpoint)\n",
    "                continue\n",
    "            print(f\"    '{marker}' at ch{ch_idx}\")\n",
    "            \n",
    "            print(\"  Extracting channel (memory-mapped)...\")\n",
    "            img, error = extract_channel_memmap(input_path, ch_idx)\n",
    "            if error:\n",
    "                print(f\"  âš ï¸  SKIP: {error}\")\n",
    "                checkpoint['results'].append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'status': 'failed',\n",
    "                    'num_crypts': 0,\n",
    "                    'time_seconds': time.time() - sample_start,\n",
    "                    'error': error\n",
    "                })\n",
    "                save_checkpoint(checkpoint)\n",
    "                continue\n",
    "            \n",
    "            print(f\"    {img.shape[0]}Ã—{img.shape[1]} px\")\n",
    "            img_shape = img.shape\n",
    "            \n",
    "            # PHASE 1: Segment & compress tiles\n",
    "            print(f\"  Segmenting with {tile_size}px tiles (RLE compression)...\")\n",
    "            tile_files, _ = segment_with_tiles_rle_compressed(img, predictor, sample_id, tile_size, OVERLAP)\n",
    "            print(f\"    â†’ {len(tile_files)} tiles saved\")\n",
    "            \n",
    "            del img\n",
    "            gc.collect()\n",
    "            \n",
    "            if len(tile_files) == 0:\n",
    "                print(\"  âš ï¸  SKIP: No tiles\")\n",
    "                checkpoint['results'].append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'status': 'failed',\n",
    "                    'num_crypts': 0,\n",
    "                    'time_seconds': time.time() - sample_start,\n",
    "                    'error': 'No tiles'\n",
    "                })\n",
    "                save_checkpoint(checkpoint)\n",
    "                continue\n",
    "            \n",
    "            # PHASE 2: Load tiles in chunks (auto-adaptive chunk size)\n",
    "            print(\"  Loading tiles (chunked + RLE decode)...\")\n",
    "            masks = load_tiles_chunked(tile_files, img_shape)  # Auto-selects chunk size\n",
    "            print(f\"    â†’ {len(masks)} masks loaded\")\n",
    "            \n",
    "            if len(masks) == 0:\n",
    "                print(\"  âš ï¸  SKIP: No masks\")\n",
    "                checkpoint['results'].append({\n",
    "                    'sample_id': sample_id,\n",
    "                    'status': 'failed',\n",
    "                    'num_crypts': 0,\n",
    "                    'time_seconds': time.time() - sample_start,\n",
    "                    'error': 'No masks'\n",
    "                })\n",
    "                save_checkpoint(checkpoint)\n",
    "                continue\n",
    "            # PHASE 3: Convert to segmentation in batches (auto-adaptive)\n",
    "            print(\"  Converting to segmentation (chunked batches)...\")\n",
    "            seg = masks_to_segmentation_chunked(masks, img_shape)  # Auto-selects batch size\n",
    "            \n",
    "            del masks\n",
    "            gc.collect()\n",
    "            \n",
    "            print(\"  Filtering by size & shape...\")\n",
    "            filt = filter_by_size_shape(seg, MIN_AREA, MAX_AREA, MAX_ECCENTRICITY)\n",
    "            print(f\"    â†’ {int(filt.max())} crypts\")\n",
    "            \n",
    "            del seg\n",
    "            gc.collect()\n",
    "            \n",
    "            if APPLY_MORPHOLOGY:\n",
    "                print(\"  Morphological refinement...\")\n",
    "                final = apply_morphological_refinement(filt, MIN_AREA, MERGE_RADIUS, SMOOTH_RADIUS)\n",
    "                n_final = int(final.max())\n",
    "                print(f\"    â†’ {n_final} crypts\")\n",
    "            else:\n",
    "                final = filt\n",
    "                n_final = int(final.max())\n",
    "            \n",
    "            del filt\n",
    "            gc.collect()\n",
    "            \n",
    "            print(\"  Saving outputs...\")\n",
    "            n_crypts = save_outputs(final, output_dir, sample_id, marker)\n",
    "            \n",
    "            del final\n",
    "            gc.collect()\n",
    "            \n",
    "            elapsed = time.time() - sample_start\n",
    "            print(f\"  âœ… {n_crypts} crypts in {elapsed:.1f}s ({elapsed/60:.1f} min)\")\n",
    "            \n",
    "            checkpoint['results'].append({\n",
    "                'sample_id': sample_id,\n",
    "                'status': 'success',\n",
    "                'num_crypts': n_crypts,\n",
    "                'time_seconds': elapsed,\n",
    "                'file_size_mb': size_mb,\n",
    "                'tile_size': tile_size,\n",
    "                'category': category,\n",
    "                'marker': marker\n",
    "            })\n",
    "            save_checkpoint(checkpoint)\n",
    "            \n",
    "            # Cleanup temp\n",
    "            try:\n",
    "                temp_sample = TEMP_DIR / sample_id\n",
    "                if temp_sample.exists():\n",
    "                    shutil.rmtree(temp_sample)\n",
    "            except:\n",
    "                pass\n",
    "            \n",
    "            # RECOVERY PAUSE\n",
    "            if idx < len(remaining_sorted):\n",
    "                print(f\"\\n  â¸  Pause {PAUSE_BETWEEN_SAMPLES}s for GC...\")\n",
    "                gc.collect()\n",
    "                time.sleep(PAUSE_BETWEEN_SAMPLES)\n",
    "            \n",
    "        except Exception as e:\n",
    "            elapsed = time.time() - sample_start\n",
    "            error_msg = f\"{type(e).__name__}: {e}\"\n",
    "            print(f\"  âœ— ERROR: {error_msg}\")\n",
    "            checkpoint['results'].append({\n",
    "                'sample_id': sample_id,\n",
    "                'status': 'failed',\n",
    "                'num_crypts': 0,\n",
    "                'time_seconds': elapsed,\n",
    "                'error': error_msg\n",
    "            })\n",
    "            save_checkpoint(checkpoint)\n",
    "        \n",
    "        finally:\n",
    "            gc.collect()\n",
    "    \n",
    "    total_time = time.time() - overall_start\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPLETE\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"Total: {total_time/60:.1f} min ({total_time/3600:.1f} h)\")\n",
    "    \n",
    "    success = [r for r in checkpoint['results'] if r.get('status') == 'success']\n",
    "    failed = [r for r in checkpoint['results'] if r.get('status') == 'failed']\n",
    "    \n",
    "    print(f\"Success: {len(success)}\")\n",
    "    print(f\"Failed: {len(failed)}\")\n",
    "    \n",
    "    if failed:\n",
    "        print(\"\\nFailed:\")\n",
    "        for r in failed:\n",
    "            print(f\"  - {r['sample_id']}: {r.get('error', 'Unknown')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ce1afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === SUMMARY ===\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"V8 BATCH SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "if CHECKPOINT_FILE.exists():\n",
    "    with open(CHECKPOINT_FILE, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    \n",
    "    results = data.get('results', [])\n",
    "    if results:\n",
    "        df = pd.DataFrame(results)\n",
    "        print(df.to_string())\n",
    "        \n",
    "        csv_path = Path(r\"C:\\Users\\researcher\\Downloads\\Cycif_pipeline_V3\\microsam_batch_summary_v8.csv\")\n",
    "        df.to_csv(csv_path, index=False)\n",
    "        print(f\"\\nâœ“ Saved: {csv_path}\")\n",
    "    else:\n",
    "        print(\"No results.\")\n",
    "else:\n",
    "    print(\"No checkpoint.\")\n",
    "\n",
    "# Cleanup temp\n",
    "if TEMP_DIR.exists():\n",
    "    try:\n",
    "        shutil.rmtree(TEMP_DIR)\n",
    "        print(f\"\\nâœ“ Cleaned: {TEMP_DIR}\")\n",
    "    except Exception as e:\n",
    "        print(f\"\\nâš ï¸  Cleanup: {e}\")\n",
    "\n",
    "print(f\"\\nFinal RAM: {psutil.virtual_memory().available / (1024**3):.1f} GB free\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "microsam-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
